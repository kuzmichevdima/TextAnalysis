{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункты 1-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import xgboost\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inp = open('SMSSpamCollection.txt', 'r')\n",
    "cl_list = []\n",
    "txt_list = []\n",
    "for line in inp:\n",
    "    cl, txt = line.split('\\t')\n",
    "    cl_list.append(1 if cl == 'spam' else 0)\n",
    "    txt_list.append(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer()\n",
    "X = countVectorizer.fit_transform(txt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93334852685794145"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(LogisticRegression(), X, cl_list, cv=10, scoring='f1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "\"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "\"Have you visited the last lecture on physics?\",\n",
    "\"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "\"Only 99$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regr = LogisticRegression()\n",
    "log_regr.fit(X, cl_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regr.predict(countVectorizer.transform(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(method):\n",
    "    results = []\n",
    "    for ngram_range in [(2, 2), (3, 3), (1, 3)]:\n",
    "        countVectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "        X = countVectorizer.fit_transform(txt_list)\n",
    "        results.append(np.mean(cross_val_score(method, X, cl_list, cv=10, scoring='f1')))\n",
    "    return map(lambda x: round(x, 2), results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.82, 0.73, 0.93]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.65, 0.38, 0.89]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidfVectorizer = TfidfVectorizer()\n",
    "X = tfidfVectorizer.fit_transform(txt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85285995541724557"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regr = LogisticRegression()\n",
    "log_regr.fit(X, cl_list)\n",
    "np.mean(cross_val_score(log_regr, X, cl_list, cv=10, scoring='f1'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "качество понизилось"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_method(ngram_range, method):\n",
    "    countVectorizer = CountVectorizer(ngram_range=ngram_range)\n",
    "    X = countVectorizer.fit_transform(txt_list)\n",
    "    return np.mean(cross_val_score(method, X, cl_list, cv=10, scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91071777042176605"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_method((1, 1), RandomForestClassifier(n_estimators=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#countVectorizer = CountVectorizer()\n",
    "#X = countVectorizer.fit_transform(txt_list)\n",
    "#print np.mean(cross_val_score(GradientBoostingClassifier(), X.toarray(), cl_list, cv=10, scoring='f1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countVectorizer = CountVectorizer()\n",
    "X = countVectorizer.fit_transform(txt_list).toarray()\n",
    "xtrain, xval, ytrain, yval = train_test_split(X, cl_list, random_state=0, test_size=.2)\n",
    "\n",
    "Xdatatrain = xgboost.DMatrix(data = xtrain, label = ytrain)\n",
    "Xdatatest = xgboost.DMatrix(data = xval, label = yval)\n",
    "watchlist = [(Xdatatrain, 'train'), (Xdatatest, 'eval')]            \n",
    "\n",
    "param = {}\n",
    "param['booster'] = 'gbtree'\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['eval_metric'] = 'logloss'\n",
    "param['silent'] = 0\n",
    "\n",
    "numround = 150\n",
    "\n",
    "plst = list(param.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.47604\teval-logloss:0.481482\n",
      "Multiple eval metrics have been passed: 'eval-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until eval-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.092936\teval-logloss:0.121982\n",
      "[20]\ttrain-logloss:0.058126\teval-logloss:0.099573\n",
      "[30]\ttrain-logloss:0.045623\teval-logloss:0.088486\n",
      "[40]\ttrain-logloss:0.038643\teval-logloss:0.082606\n",
      "[50]\ttrain-logloss:0.033865\teval-logloss:0.078594\n",
      "[60]\ttrain-logloss:0.029991\teval-logloss:0.075876\n",
      "[70]\ttrain-logloss:0.027444\teval-logloss:0.076249\n",
      "[80]\ttrain-logloss:0.025269\teval-logloss:0.075936\n",
      "[90]\ttrain-logloss:0.023679\teval-logloss:0.076031\n",
      "[100]\ttrain-logloss:0.022602\teval-logloss:0.076136\n",
      "[110]\ttrain-logloss:0.02153\teval-logloss:0.075852\n",
      "[120]\ttrain-logloss:0.020388\teval-logloss:0.075817\n",
      "[130]\ttrain-logloss:0.019238\teval-logloss:0.076924\n",
      "[140]\ttrain-logloss:0.018539\teval-logloss:0.076816\n",
      "final score = 0.0781032709326\n"
     ]
    }
   ],
   "source": [
    "bst = xgboost.train(plst, Xdatatrain, numround, evals = watchlist,  early_stopping_rounds=50, verbose_eval = 10)\n",
    "score = log_loss(yval, bst.predict(Xdatatest))\n",
    "print \"final score = {}\".format(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final xgboost (no tuning) score = 0.921896729067\n"
     ]
    }
   ],
   "source": [
    "print \"final xgboost (no tuning) score = {}\".format(1-score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пункт 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дано мало примеров, мы для них получаем количество фич, существенно превышающее кол-во примеров, поэтому сложным методам не хватает информации для качественного обучения; простейшая модель логистической регрессии дает лучший результат из всего испробованного. Если генерировать больше фич (2 и 3 н-граммы), то прироста это не дает опять же из-за малого количества сэпмлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
